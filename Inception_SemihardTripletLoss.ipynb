{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inception_SemihardTripletLoss.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l5nNQVhBFI8",
        "colab_type": "code",
        "outputId": "aae89657-e878-4dff-8465-13518fae1462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#import keras\n",
        "import matplotlib.pyplot as plt\n",
        "#import cv2\n",
        "#from keras.models import Model\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import math\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi0p57v4BJo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir /content/.kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "os.path.dirname('.kaggle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2GcG7ruBOtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"shreegowri\",\"key\":\"f70a15b60d31ba3eb431bb708868ff16\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump({\"username\":\"shreegowri\",\"key\":\"f70a15b60d31ba3eb431bb708868ff16\"}, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03BslBQpBQOH",
        "colab_type": "code",
        "outputId": "796462d1-8a4c-4550-8ec3-869e57e061b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c ifood-2019-fgvc6 #downloads the files into /content/{/content}/competitions/ifood-2019-fgvc6 directory"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: {/content}\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading val_set.zip to {/content}/competitions/ifood-2019-fgvc6\n",
            " 92% 203M/221M [00:04<00:00, 32.9MB/s]\n",
            "100% 221M/221M [00:04<00:00, 52.9MB/s]\n",
            "Downloading train_labels.csv.zip to {/content}/competitions/ifood-2019-fgvc6\n",
            "  0% 0.00/262k [00:00<?, ?B/s]\n",
            "100% 262k/262k [00:00<00:00, 73.3MB/s]\n",
            "Downloading test_set.zip to {/content}/competitions/ifood-2019-fgvc6\n",
            " 98% 514M/526M [00:08<00:00, 68.5MB/s]\n",
            "100% 526M/526M [00:08<00:00, 65.0MB/s]\n",
            "Downloading sample_submission.csv to {/content}/competitions/ifood-2019-fgvc6\n",
            "  0% 0.00/554k [00:00<?, ?B/s]\n",
            "100% 554k/554k [00:00<00:00, 76.3MB/s]\n",
            "Downloading ifood2019_sample_submission.csv to {/content}/competitions/ifood-2019-fgvc6\n",
            "  0% 0.00/554k [00:00<?, ?B/s]\n",
            "100% 554k/554k [00:00<00:00, 75.3MB/s]\n",
            "Downloading class_list.txt to {/content}/competitions/ifood-2019-fgvc6\n",
            "  0% 0.00/3.63k [00:00<?, ?B/s]\n",
            "100% 3.63k/3.63k [00:00<00:00, 3.24MB/s]\n",
            "Downloading train_set.zip to {/content}/competitions/ifood-2019-fgvc6\n",
            "100% 2.12G/2.12G [00:44<00:00, 73.9MB/s]\n",
            "100% 2.12G/2.12G [00:44<00:00, 51.1MB/s]\n",
            "Downloading val_labels.csv to {/content}/competitions/ifood-2019-fgvc6\n",
            "  0% 0.00/217k [00:00<?, ?B/s]\n",
            "100% 217k/217k [00:00<00:00, 71.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apUvOTbABSHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "train_zip = '/content/{/content}/competitions/ifood-2019-fgvc6/train_set.zip'\n",
        "zip_ref = zipfile.ZipFile(train_zip, 'r')\n",
        "zip_ref.extractall('train_set')\n",
        "\n",
        "\n",
        "train_label_zip = '/content/{/content}/competitions/ifood-2019-fgvc6/train_labels.csv.zip'\n",
        "zip_ref = zipfile.ZipFile(train_label_zip, 'r')\n",
        "zip_ref.extractall('train_set/train_set')\n",
        "\n",
        "\n",
        "val_zip = '/content/{/content}/competitions/ifood-2019-fgvc6/val_set.zip'\n",
        "zip_ref = zipfile.ZipFile(val_zip, 'r')\n",
        "zip_ref.extractall('val_set')\n",
        "\n",
        "test_zip = '/content/{/content}/competitions/ifood-2019-fgvc6/test_set.zip'\n",
        "zip_ref = zipfile.ZipFile(test_zip, 'r')\n",
        "zip_ref.extractall('test_set')\n",
        "\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np1llC8WBV3Z",
        "colab_type": "code",
        "outputId": "b7c973f6-d537-4b03-a98e-7d61ab9198b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def load_csv(filename):\n",
        "  ''' param: filename of the csv file with train or test images names along with respective labels\n",
        "      return: the path to images and respective labels of the images\n",
        "  '''\n",
        "  dirname = os.path.dirname(filename)\n",
        "  images_path = []\n",
        "  labels = []\n",
        "  with open(filename) as f:\n",
        "    parsed = csv.reader(f, delimiter=\",\", quotechar=\"'\")\n",
        "    for row in parsed:\n",
        "      if row[1]=='label':\n",
        "        continue\n",
        "      images_path.append(os.path.join(dirname, row[0]))\n",
        "      #print(row[1])\n",
        "      labels.append(int(row[1]))\n",
        "  return images_path, labels\n",
        "train_images_path, train_labels = load_csv('/content/train_set/train_set/train_labels.csv')\n",
        "val_images_path, val_labels = load_csv ('/content/val_set/val_set/val_labels.csv')\n",
        "print(len(train_labels))\n",
        "class_names = np.loadtxt('/content/class_list.txt', dtype={'names': ('class_num', 'class_name',), 'formats': ('i4', 'U100')})\n",
        "class_names[0][1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'macaron'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdRRXA0LB94w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input_shape = (3, IMAGE_SIZE, IMAGE_SIZE)\n",
        "HEIGHT = 299\n",
        "WIDTH = 299\n",
        "IMG_SHAPE = (HEIGHT, WIDTH, 3)\n",
        "resize_height = 299\n",
        "resize_height = 299\n",
        "means = [123.68, 116.779, 103.939] #ImageNet's mean, change to training data mean\n",
        "\n",
        "def preprocess_train(x,y):\n",
        "  ''' param: path to the image with its label\n",
        "      task: reads image from directory, resizes an image to 256 x 256, then randomly crops to 224 x 224\n",
        "      return: the augmented and centered data\n",
        "  '''\n",
        "  x = tf.io.read_file(x) #read images\n",
        "  x = tf.image.decode_jpeg(x, dct_method=\"INTEGER_ACCURATE\", channels=3) #decode jpeg images\n",
        "  x = tf.image.convert_image_dtype(x, tf.float32)\n",
        "  x = tf.image.resize(x, (resize_height, resize_height), antialias=False) #Resizes an image to a target width and height by keeping the aspect ratio the same without distortion.\n",
        "  #x = tf.image.random_crop(x, [HEIGHT, WIDTH, 3]) #Randomly crops a tensor to a given size\n",
        "  #x = tf.image.central_crop(x, 0.875)  #as we 224/256 = 0.875 central cropping the image\n",
        "  #x = tf.image.random_flip_left_right(x)  #flips the image along width with 0.5 probability\n",
        "  x = tf.keras.applications.inception_v3.preprocess_input(x)\n",
        "  return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQo9VuW3B-_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_val(x,y):\n",
        "  ''' similar to preprocess_train but uses center crop after resize\n",
        "  '''\n",
        "  x = tf.io.read_file(x)\n",
        "  x = tf.image.decode_jpeg(x, dct_method=\"INTEGER_ACCURATE\", channels=3)\n",
        "  x = tf.image.convert_image_dtype(x, tf.float32)\n",
        "  x = tf.image.resize(x, [resize_height, resize_height], antialias=False)\n",
        "  #x = tf.image.resize_with_pad(x, resize_height, resize_height, antialias=False)\n",
        "  #x = tf.image.central_crop(x, 0.875)  #as we 224/256 = 0.875 central cropping the image\n",
        "  x = tf.keras.applications.inception_v3.preprocess_input(x)\n",
        "  return x,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN7GL27PCCJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the TF datset with batchsize, shuffling and preprocessing\n",
        "BATCH_SIZE = 64 #change and see if performance improves, 1024 resource not enough\n",
        "num_train_examples = len(train_images_path)\n",
        "Num_Classes = len(set(train_labels))\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images_path, train_labels)).shuffle(8000, reshuffle_each_iteration=True).map(preprocess_train, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images_path, val_labels)).map(preprocess_val).batch(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3br3IoFmCFA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.InceptionV3(input_shape=(299,299,3), weights = \"imagenet\", include_top = False) #input_shape = (224,224,3),\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable=True\n",
        "#last_layer = base_model.get_layer('post_relu')\n",
        "last_output = base_model.layers[-1].output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(last_output)\n",
        "#x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(128, activation= None, name='dense_layer_1')(x)\n",
        "x = tf.keras.layers.Lambda(lambda y: tf.math.l2_normalize(y, axis=1))(x)\n",
        "model = tf.keras.models.Model(base_model.input, x, name='model_embedding')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2y9OQu-CLxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "#Adding tensorboard callbacks\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import datetime\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, update_freq='batch', histogram_freq=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zubMHGoDCWG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the model\n",
        "\n",
        "num_epochs = 10\n",
        "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9), loss = tfa.losses.TripletSemiHardLoss(), metrics=['accuracy'])\n",
        "#saves the model after every epoch\n",
        "cp_path = \"/content/drive/My Drive/training_val_tp/cp.ckpt\" #path to save the model\n",
        "cp_dir = os.path.dirname(cp_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=cp_path, save_weights_only=True,  period=2, verbose=1)\n",
        "model.save_weights(cp_path.format(epoch=0))\n",
        "history = model.fit(train_dataset, epochs = num_epochs, validation_data = val_dataset, callbacks = [tensorboard_callback, cp_callback])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEbZD98eUgrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2cegwMQ3U_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me-EdWM0loUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the model_1 network\n",
        "val_results = model2.predict(val_dataset)\n",
        "\n",
        "val_labels = np.array([]).astype(int)\n",
        "for element in val_dataset.as_numpy_iterator(): \n",
        "  val_labels = np.append(val_labels, element[1])\n",
        "import io\n",
        "import tensorflow_datasets as tfds\n",
        "# Save test embeddings for visualization in projector\n",
        "np.savetxt(\"vecs.tsv\", val_results, delimiter='\\t')\n",
        "\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for img, labels in tfds.as_numpy(val_dataset):\n",
        "    [out_m.write(str(x) + \"\\n\") for x in labels]\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BArfJlVrCMKO",
        "colab_type": "code",
        "outputId": "3b5a22c4-1672-4b48-e2c8-52a0273f4c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "model_2.load_weights('/content/checkpoints/incp')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7f261e6a5ef0> and <tensorflow.python.keras.layers.core.Dropout object at 0x7f261e6a5d30>).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f261cd14048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V9SNfLNmPL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = tf.nn.softmax(model_2.predict(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdRPV6cmmUOF",
        "colab_type": "code",
        "outputId": "9a81059f-b7e3-4a18-99b6-cac67ab1b3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "tf.reduce_sum(predictions, axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
              "array([1.0000001 , 1.0000001 , 0.9999999 , 1.0000001 , 0.9999999 ,\n",
              "       1.        , 1.        , 0.99999994, 0.9999999 , 0.99999994,\n",
              "       0.9999999 , 1.0000001 , 0.9999997 , 0.99999976, 1.0000002 ,\n",
              "       1.        , 0.99999994, 1.        , 1.0000004 , 0.9999996 ,\n",
              "       1.        , 1.        , 0.9999999 , 1.        , 1.        ,\n",
              "       1.0000001 , 1.0000001 , 0.9999999 , 1.0000001 , 1.        ,\n",
              "       1.        , 0.9999998 , 1.0000001 , 0.9999999 , 1.        ,\n",
              "       1.0000001 , 1.        , 0.9999999 , 1.0000001 , 1.        ,\n",
              "       1.0000001 , 1.0000001 , 1.0000001 , 1.        , 1.0000001 ,\n",
              "       1.0000001 , 0.99999994, 0.99999994, 1.0000001 , 1.        ,\n",
              "       1.0000002 , 0.9999999 , 1.0000001 , 0.9999998 , 1.        ,\n",
              "       1.0000001 , 1.        , 0.9999998 , 1.        , 1.0000001 ,\n",
              "       1.0000001 , 1.0000001 , 0.9999997 , 1.0000002 ], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}