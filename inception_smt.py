# -*- coding: utf-8 -*-
"""Inception_SMT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DPByj3DhAucb4YQzuVLf6iEoZDY-IeHT
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import os
import csv
import tensorflow as tf
from tensorflow import keras
#import keras
import matplotlib.pyplot as plt
#import cv2
#from keras.models import Model
from tensorflow.keras import Model
import numpy as np
import tensorflow_addons as tfa
import math
tf.__version__

!pip install -q pyyaml h5py  # save models in HDF5 format

from google.colab import drive
drive.mount('/content/gdrive')

import zipfile

train_zip = '/content/gdrive/My Drive/CS7140/train_set.zip'
zip_ref = zipfile.ZipFile(train_zip, 'r')
zip_ref.extractall('train_set')


train_label_zip = '/content/gdrive/My Drive/CS7140/train_labels.csv.zip'
zip_ref = zipfile.ZipFile(train_label_zip, 'r')
zip_ref.extractall('train_set/train_set')


val_zip = '/content/gdrive/My Drive/CS7140/val_set.zip'
zip_ref = zipfile.ZipFile(val_zip, 'r')
zip_ref.extractall('val_set')

test_zip = '/content/gdrive/My Drive/CS7140/test_set.zip'
zip_ref = zipfile.ZipFile(test_zip, 'r')
zip_ref.extractall('test_set')

val_labels_zip = '/content/gdrive/My Drive/CS7140/val_labels.csv.zip'
zip_ref = zipfile.ZipFile(val_labels_zip, 'r')
zip_ref.extractall('val_set/val_set')

class_list_zip = '/content/gdrive/My Drive/CS7140/class_list.txt.zip'
zip_ref = zipfile.ZipFile(class_list_zip, 'r')
zip_ref.extractall('')

zip_ref.close()



def load_csv(filename):
  ''' param: filename of the csv file with train or test images names along with respective labels
      return: the path to images and respective labels of the images
  '''
  dirname = os.path.dirname(filename)
  images_path = []
  labels = []
  with open(filename) as f:
    parsed = csv.reader(f, delimiter=",", quotechar="'")
    for row in parsed:
      if row[1]=='label':
        continue
      images_path.append(os.path.join(dirname, row[0]))
      #print(row[1])
      labels.append(int(row[1]))
  return images_path, labels
train_images_path, train_labels = load_csv('/content/train_set/train_set/train_labels.csv')
val_images_path, val_labels = load_csv ('/content/val_set/val_set/val_labels.csv')
print(len(train_labels))
class_names = np.loadtxt('/content/class_list.txt', dtype={'names': ('class_num', 'class_name',), 'formats': ('i4', 'U100')})
class_names[0][1]

#input_shape = (3, IMAGE_SIZE, IMAGE_SIZE)
HEIGHT = 299
WIDTH = 299
IMG_SHAPE = (HEIGHT, WIDTH, 3)
resize_height = 299
resize_height = 299
means = [123.68, 116.779, 103.939] #ImageNet's mean, change to training data mean

def preprocess_train(x,y):
  ''' param: path to the image with its label
      task: reads image from directory, resizes an image to 256 x 256, then randomly crops to 224 x 224
      return: the augmented and centered data
  '''
  x = tf.io.read_file(x) #read images
  x = tf.image.decode_jpeg(x, dct_method="INTEGER_ACCURATE", channels=3) #decode jpeg images
  x = tf.image.convert_image_dtype(x, tf.float32)
  x = tf.image.resize(x, (resize_height, resize_height), antialias=False) #Resizes an image to a target width and height by keeping the aspect ratio the same without distortion.
  #x = tf.image.random_crop(x, [HEIGHT, WIDTH, 3]) #Randomly crops a tensor to a given size
  #x = tf.image.central_crop(x, 0.875)  #as we 224/256 = 0.875 central cropping the image
  #x = tf.image.random_flip_left_right(x)  #flips the image along width with 0.5 probability
  x = tf.keras.applications.inception_v3.preprocess_input(x)
  return x,y

def preprocess_val(x,y):
  ''' similar to preprocess_train but uses center crop after resize
  '''
  x = tf.io.read_file(x)
  x = tf.image.decode_jpeg(x, dct_method="INTEGER_ACCURATE", channels=3)
  x = tf.image.convert_image_dtype(x, tf.float32)
  x = tf.image.resize(x, [resize_height, resize_height], antialias=False)
  #x = tf.image.resize_with_pad(x, resize_height, resize_height, antialias=False)
  #x = tf.image.central_crop(x, 0.875)  #as we 224/256 = 0.875 central cropping the image
  x = tf.keras.applications.inception_v3.preprocess_input(x)
  return x,y

#define the TF datset with batchsize, shuffling and preprocessing
BATCH_SIZE = 32 #change and see if performance improves, 1024 resource not enough
num_train_examples = len(train_images_path)
Num_Classes = len(set(train_labels))
train_dataset = tf.data.Dataset.from_tensor_slices((train_images_path, train_labels)).shuffle(4000, reshuffle_each_iteration=True).map(preprocess_train, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)
val_dataset = tf.data.Dataset.from_tensor_slices((val_images_path, val_labels)).map(preprocess_val).batch(128)

for img,lab in train_dataset.take(1):
  labs = lab
np.unique(labs.numpy(), return_counts=True)

base_model = tf.keras.applications.InceptionV3(input_shape=(299,299,3), weights = "imagenet", include_top = False) #input_shape = (224,224,3),
for layer in base_model.layers:
  layer.trainable=True
#last_layer = base_model.get_layer('post_relu')
last_output = base_model.layers[-1].output


x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(last_output)
x = tf.keras.layers.Flatten()(x)
x1 = tf.keras.layers.Dense(128, activation= None, name='dense_layer_1')(x) # No activation on final dense layer
x = tf.keras.layers.Lambda(lambda y: tf.math.l2_normalize(y, axis=1))(x1) # L2 normalize embeddings
model_1 = tf.keras.models.Model(base_model.input, x, name='model_embedding')  #Embedding model for triplet loss

x2 = tf.keras.layers.Dense(251, activation= 'relu', name='dense_layer_2')(x1)
model_2 = tf.keras.models.Model(base_model.input, x2, name='model_softmax')  #Classifier model for crossentropy loss

model_2.summary()

loss_object1 = tfa.losses.TripletSemiHardLoss()
loss_object2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

def loss(model, x, y, training, typ):
  # training=training is needed only if there are layers with different
  # behavior during training versus inference (e.g. Dropout).
  y_ = model(x, training=training)
  if typ == 1:
    return loss_object1(y_true=y, y_pred=y_)
  if typ == 2:
    return loss_object2(y_true=y, y_pred=y_)

#l = loss(model, features, labels, training=False)

#For GradientTape
def grad(model1, model2, inputs, targets):
  with tf.GradientTape() as tape:
    loss_1 = loss(model1, inputs, targets, training=True, typ = 1)
    if math.isnan(loss_1):
      loss_1 = 0.00001
    loss_2 = loss(model2, inputs, targets, training=True, typ = 2)
    loss_value = tf.reduce_sum(loss_1 + loss_2)
  return loss_value, tape.gradient(loss_value, model2.trainable_variables)

#define optimizer
optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)

train_loss_results = []
train_accuracy_results = []
val_accuracy_results = []

num_epochs = 100

for epoch in range(num_epochs):
  epoch_loss_avg = tf.keras.metrics.Mean()
  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy() #fn(y_true, y_pred)
  val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()
  cnt = 0

  # Training loop - using batches of 512
  for x, y in train_dataset:
    cnt +=1
    # Optimize the model
    loss_value, grads = grad(model_1, model_2, x, y)
    optimizer.apply_gradients(zip(grads, model_2.trainable_variables))
    if cnt % 1000 == 0:
      print(loss_value)

    # Track progress
    epoch_loss_avg.update_state(loss_value)  # Add current batch loss
    # Compare predicted label to actual label
    # training=True is needed only if there are layers with different
    # behavior during training versus inference (e.g. Dropout).
    epoch_accuracy.update_state(y, model_2(x, training=True))

  # End of epoch, update per epoch metrics
  train_loss_results.append(epoch_loss_avg.result())
  train_accuracy_results.append(epoch_accuracy.result())

    #Accuracy on validation set
  for x, y in val_dataset:
    val_accuracy.update_state(y, model_2(x, training=False))
  
  # End of epoch, update per epoch accuracy
  val_accuracy_results.append(val_accuracy.result())

  #show result per 5 epochs
  if epoch % 2 == 0:
    print("Epoch {:03d}: Loss: {:.3f}, Train Accuracy: {:.3%}, Validation Accuracy: {:.3%}".format(epoch,
                                                                epoch_loss_avg.result(),
                                                                epoch_accuracy.result(), val_accuracy.result()))
    model_2.save_weights('/content/drive/My Drive/AML_Project/checkpoints/incp')  #save to drive

np.savetxt("val_accuracy_incp.csv", val_accuracy_results, delimiter=',', fmt='%f', header="ACC", comments="")
np.savetxt("train_accuracy_incp.csv", train_accuracy_results, delimiter=',', fmt='%f', header="ACC", comments="")

train_dataset = tf.data.Dataset.from_tensor_slices((train_images_path, train_labels)).map(preprocess_train).batch(BATCH_SIZE)

# Evaluate the model_1 network
val_results = model_1.predict(val_dataset)
train_results = model_1.predict(train_dataset)

val_labels = np.array([]).astype(int)
for element in val_dataset.as_numpy_iterator(): 
  val_labels = np.append(val_labels, element[1])

train_labels = np.array([]).astype(int)
for element in train_dataset.as_numpy_iterator(): 
  train_labels = np.append(train_labels, element[1])

np.savetxt("validation_embedding_incp.csv", val_results, delimiter=',', fmt='%f', header="Emd,"*128, comments="")
np.savetxt("train_embedding_incp.csv", train_results, delimiter=',', fmt='%f', header="Emd,"*128, comments="")
np.savetxt("validation_labels_incp.csv", val_labels, delimiter=',', fmt='%d', header="label", comments="")
np.savetxt("train_labels_incp.csv", train_labels, delimiter=',', fmt='%d', header="label", comments="")

import io
import tensorflow_datasets as tfds
# Save test embeddings for visualization in projector
np.savetxt("vecs_incp.tsv", val_results, delimiter='\t')

out_m = io.open('meta_incp.tsv', 'w', encoding='utf-8')
for img, labels in tfds.as_numpy(val_dataset):
    [out_m.write(str(x) + "\n") for x in labels]
out_m.close()


try:
  from google.colab import files
  files.download('vecs_incp.tsv')
  files.download('meta_incp.tsv')
except:
  pass